{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Query by Vocal Imitation: Submission Template\n",
    "\n",
    "⚠️⚠️⚠️ This template is a draft and still subject to change ⚠️⚠️⚠️\n",
    "\n",
    "This is the submission template for the Query by Vocal Imitation challenge at the 2025 AES International Conference on Artificial Intelligence and Machine Learning for Audio.\n",
    "\n",
    "Instructions are contained in the code and comments, so please read them carefully. You should only modify a single code block and leave the others untouched."
   ],
   "id": "12ffc8a5f4990014"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK.\n",
    "\"\"\"\n",
    "\n",
    "!pip install -q \"numpy<2\" tqdm soundfile resampy"
   ],
   "id": "5e7c86e43bf5fd48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This block contains the abstract base class `QBVModel`, which you should subclass to wrap your model.",
   "id": "c1acf118dd3d91de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK.\n",
    "\"\"\"\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "class QBVModel(ABC):\n",
    "    @abstractmethod\n",
    "    def embed_item(self, audio: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Generate an embedding for a single audio recording.\n",
    "\n",
    "        Args:\n",
    "            audio (np.ndarray): One-dimensional numpy array containing the audio to be embedded.\n",
    "\n",
    "        Returns:\n",
    "            embedding (np.ndarray): One-dimensional numpy array containing the generated embedding.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def compute_scores(\n",
    "            self, embedding_files: dict[str, str], queries: dict[str, np.ndarray]\n",
    "    ) -> dict[str, dict[str, float]]:\n",
    "        \"\"\"Compute similarity scores given the previously calculated embeddings and a set of queries.\n",
    "\n",
    "        Each <embedding, query> pairing should be assigned a single floating point score, where higher\n",
    "        scores indicate higher similarity.\n",
    "\n",
    "        Args:\n",
    "            embedding_files (dict[str, str]): A dictionary mapping item ids to the file containing the\n",
    "                corresponding embedding.\n",
    "            queries (dict[str, np.ndarray]): A dictionary mapping query ids to the corresponding audio\n",
    "\n",
    "        Returns:\n",
    "            scores (dict[str, dict[str, float]]): A dictionary mapping query ids to a dictionary of item\n",
    "                ids and their corresponding similarity scores. E.g:\n",
    "                {\n",
    "                    \"query_1\": {\n",
    "                        \"item_1\": 0.8,\n",
    "                        \"item_2\": 0.6,\n",
    "                        ...\n",
    "                    },\n",
    "                    \"query_2\": {\n",
    "                        \"item_1\": 0.4,\n",
    "                        \"item_2\": 0.9,\n",
    "                        ...\n",
    "                    },\n",
    "                    ...\n",
    "                }\n",
    "        \"\"\"\n",
    "        pass"
   ],
   "id": "184c7ab5b6f8896c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The following block contains a baseline implementation of a VGGish model as used in [1] to illustrate the expected structure of the model class.\n",
    "\n",
    "[1] https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8683461"
   ],
   "id": "54d1fd97620ea4bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK.\n",
    "\"\"\"\n",
    "\n",
    "!pip install torchaudio torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from numpy.linalg import norm\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class M_VGGish(nn.Module, QBVModel):\n",
    "    def __init__(self):\n",
    "        super(M_VGGish, self).__init__()\n",
    "        self.model = torch.hub.load('harritaylor/torchvggish', 'vggish')\n",
    "        self.model.postprocess = False\n",
    "        self.l5 = self.model.features[:12]\n",
    "        self.l6 = self.model.features[:14]\n",
    "\n",
    "        self.sr = SAMPLE_RATE\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model._preprocess(x, self.sr).to(self.device)\n",
    "\n",
    "        x1 = self.l5(x).reshape(len(x), -1)\n",
    "        x2 = self.l6(x).reshape(len(x), -1)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = x.mean(dim=0)[None, :]\n",
    "        return x\n",
    "\n",
    "    def embed_item(self, item):\n",
    "        return self(item).detach().squeeze().cpu().numpy()\n",
    "\n",
    "    def compute_scores(self, embedding_files, queries):\n",
    "        scores = {key: {} for key in queries}\n",
    "\n",
    "        query_embs = {key: self.embed_item(val) for key, val in queries.items()}\n",
    "\n",
    "        for item, emb_file in tqdm(embedding_files.items()):\n",
    "            embedding = np.load(emb_file)\n",
    "            for query_name, query_emb in query_embs.items():\n",
    "                sim = np.dot(embedding, query_emb) / (norm(embedding) * norm(query_emb))\n",
    "                scores[query_name][item] = sim.item()\n",
    "        return scores\n"
   ],
   "id": "8b67cd215ca687bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### TODO: Provide download utilities for submissions (git repos, checkpoints etc.)",
   "id": "bc002b30453509d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "CHANGE THIS BLOCK: Download any resources you require in this block, and implement and instantiate your model.\n",
    "\"\"\"\n",
    "\n",
    "# class YourAwesomeModel(QBVModel):\n",
    "#     def embed_item(self, audio: np.ndarray) -> np.ndarray:\n",
    "#         pass\n",
    "#\n",
    "#     def compute_scores(\n",
    "#         self, embedding_files: dict[str, str], queries: dict[str, np.ndarray]\n",
    "#     ) -> dict[str, dict[str, float]]:\n",
    "#         pass\n",
    "\n",
    "qbv_model = M_VGGish()"
   ],
   "id": "4b2e8b7fcd33f47c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK. This block calls your model to generate embeddings and compute scores. Make sure that your model is able to run this block without any errors.\n",
    "\"\"\"\n",
    "\n",
    "items_path = \"items\"\n",
    "embeddings_path = \"embeddings\"\n",
    "queries_path = \"queries\"\n",
    "\n",
    "embedding_files = {}\n",
    "query_files = {}\n",
    "\n",
    "import os, glob, json\n",
    "from resampy import resample\n",
    "\n",
    "for item in glob.glob(os.path.join(items_path, \"*.wav\")):\n",
    "    item_name = os.path.splitext(os.path.basename(item))[0]\n",
    "    audio, sr = sf.read(item)\n",
    "    audio = resample(audio, sr, SAMPLE_RATE)\n",
    "    emb = qbv_model.embed_item(audio)\n",
    "\n",
    "    emb_file = os.path.join(embeddings_path, item_name + \".npy\")\n",
    "    np.save(emb_file, emb)\n",
    "\n",
    "    embedding_files[item_name] = emb_file\n",
    "\n",
    "for query in glob.glob(os.path.join(queries_path, \"*.wav\")):\n",
    "    query_name = os.path.splitext(os.path.basename(query))[0]\n",
    "    audio, sr = sf.read(query)\n",
    "    audio = resample(audio, sr, SAMPLE_RATE)\n",
    "    query_files[query_name] = audio\n",
    "\n",
    "scores = qbv_model.compute_scores(embedding_files, query_files)\n",
    "\n",
    "with open(\"scores.json\", \"w\") as f:\n",
    "    json.dump(scores, f)\n"
   ],
   "id": "6c13789ece5b1830",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
