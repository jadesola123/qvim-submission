{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d59b002",
   "metadata": {},
   "source": [
    "# Confidentiality Statement\n",
    "\n",
    "As the organizers of this contest, we assure all participants that their submitted models and code will be treated with strict confidentiality. \n",
    "\n",
    "Submissions will only be accessed by the designated review team for evaluation purposes and will not be shared, distributed, or used beyond the scope of this challenge.\n",
    "\n",
    "Participants retain full ownership of their work. We will not claim any rights over the submitted materials, nor will we use them for any purpose outside of the challenge evaluation process.\n",
    "\n",
    "We appreciate your participation in this challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ffc8a5f4990014",
   "metadata": {},
   "source": [
    "# Query by Vocal Imitation: Submission Template\n",
    "\n",
    "\n",
    "This is the submission template for the Query by Vocal Imitation challenge at the 2025 AES International Conference on Artificial Intelligence and Machine Learning for Audio.\n",
    "\n",
    "Instructions are contained in the code and comments, so please read them carefully. You should only modify a single code block and leave the others untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c86e43bf5fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK.\n",
    "\"\"\"\n",
    "\n",
    "!pip install -q \"numpy<2\" tqdm soundfile resampy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1acf118dd3d91de",
   "metadata": {},
   "source": [
    "This block contains the abstract base class `QBVModel`, which you should subclass to wrap your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c7ab5b6f8896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK.\n",
    "\"\"\"\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "class QBVModel(ABC):\n",
    "    @abstractmethod\n",
    "    def embed_item(self, audio: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Generate an embedding for a single audio recording.\n",
    "\n",
    "        Args:\n",
    "            audio (np.ndarray): One-dimensional numpy array containing the audio to be embedded.\n",
    "\n",
    "        Returns:\n",
    "            embedding (np.ndarray): One-dimensional numpy array containing the generated embedding.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def compute_scores(\n",
    "            self, embedding_files: dict[str, str], queries: dict[str, np.ndarray]\n",
    "    ) -> dict[str, dict[str, float]]:\n",
    "        \"\"\"Compute similarity scores given the previously calculated embeddings and a set of queries.\n",
    "\n",
    "        Each <embedding, query> pairing should be assigned a single floating point score, where higher\n",
    "        scores indicate higher similarity.\n",
    "\n",
    "        Args:\n",
    "            embedding_files (dict[str, str]): A dictionary mapping item ids to the file containing the\n",
    "                corresponding embedding.\n",
    "            queries (dict[str, np.ndarray]): A dictionary mapping query ids to the corresponding audio\n",
    "\n",
    "        Returns:\n",
    "            scores (dict[str, dict[str, float]]): A dictionary mapping query ids to a dictionary of item\n",
    "                ids and their corresponding similarity scores. E.g:\n",
    "                {\n",
    "                    \"query_1\": {\n",
    "                        \"item_1\": 0.8,\n",
    "                        \"item_2\": 0.6,\n",
    "                        ...\n",
    "                    },\n",
    "                    \"query_2\": {\n",
    "                        \"item_1\": 0.4,\n",
    "                        \"item_2\": 0.9,\n",
    "                        ...\n",
    "                    },\n",
    "                    ...\n",
    "                }\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71e7726",
   "metadata": {},
   "source": [
    "The following block contains a baseline implementation of a MobileNetV3 model as used in [1] to illustrate the expected structure of the model class.\n",
    "\n",
    "[1] https://dcase.community/documents/workshop2024/proceedings/DCASE2024Workshop_Greif_36.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4969c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK.\n",
    "\"\"\"\n",
    "\n",
    "!git clone https://github.com/jonathan-greif/qbv.git\n",
    "!pip install pandas torchaudio torch torchvision pytorch-lightning==1.9.4\n",
    "\n",
    "\n",
    "from qbv.helpers.get_module import get_module\n",
    "from qbv.helpers.utils_test import get_single_emb, padding\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from numpy.linalg import norm\n",
    "\n",
    "class MobileNetV3(nn.Module, QBVModel):\n",
    "    def __init__(self):\n",
    "        super(MobileNetV3, self).__init__()\n",
    "        self.model,_,_ = get_module(\"MN\", False, False,\n",
    "                                 \"\", (None, None))\n",
    "        self.sr = SAMPLE_RATE\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = padding(x, 32000, 10)\n",
    "        x = torch.from_numpy(x)\n",
    "        embedding = get_single_emb(self.model, \"MN\", x)\n",
    "        return embedding\n",
    "    \n",
    "    def embed_item(self, item):\n",
    "        return self(item).detach().squeeze().cpu().numpy()\n",
    "\n",
    "    def compute_scores(self, embedding_files, queries):\n",
    "        scores = {key: {} for key in queries}\n",
    "\n",
    "        query_embs = {key: self.embed_item(val) for key, val in queries.items()}\n",
    "\n",
    "        for item, emb_file in tqdm(embedding_files.items()):\n",
    "            embedding = np.load(emb_file)\n",
    "            for query_name, query_emb in query_embs.items():\n",
    "                sim = np.dot(embedding, query_emb) / (norm(embedding) * norm(query_emb))\n",
    "                scores[query_name][item] = sim.item()\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc002b30453509d9",
   "metadata": {},
   "source": [
    "### TODO: Change the bottom block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e8b7fcd33f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CHANGE THIS BLOCK: Download any resources you require in this block (git repos, checkpoints etc.), and implement and instantiate your model.\n",
    "\"\"\"\n",
    "\n",
    "# class YourAwesomeModel(QBVModel):\n",
    "#     def embed_item(self, audio: np.ndarray) -> np.ndarray:\n",
    "#         pass\n",
    "#\n",
    "#     def compute_scores(\n",
    "#         self, embedding_files: dict[str, str], queries: dict[str, np.ndarray]\n",
    "#     ) -> dict[str, dict[str, float]]:\n",
    "#         pass\n",
    "\n",
    "qbv_model = MobileNetV3()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39d1e74",
   "metadata": {},
   "source": [
    "### Test Block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13789ece5b1830",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK. This block calls your model to generate embeddings and compute scores. Make sure that your model is able to run this block without any errors.\n",
    "\"\"\"\n",
    "\n",
    "items_path = \"items\"\n",
    "embeddings_path = \"embeddings\"\n",
    "queries_path = \"queries\"\n",
    "\n",
    "embedding_files = {}\n",
    "query_files = {}\n",
    "\n",
    "import os, glob, json\n",
    "from resampy import resample\n",
    "import soundfile as sf\n",
    "\n",
    "for item in glob.glob(os.path.join(items_path, \"*.wav\")):\n",
    "    item_name = os.path.splitext(os.path.basename(item))[0]\n",
    "    audio, sr = sf.read(item)\n",
    "    audio = resample(audio, sr, SAMPLE_RATE)\n",
    "    emb = qbv_model.embed_item(audio)\n",
    "\n",
    "    emb_file = os.path.join(embeddings_path, item_name + \".npy\")\n",
    "    np.save(emb_file, emb)\n",
    "\n",
    "    embedding_files[item_name] = emb_file\n",
    "\n",
    "for query in glob.glob(os.path.join(queries_path, \"*.wav\")):\n",
    "    query_name = os.path.splitext(os.path.basename(query))[0]\n",
    "    audio, sr = sf.read(query)\n",
    "    audio = resample(audio, sr, SAMPLE_RATE)\n",
    "    query_files[query_name] = audio\n",
    "\n",
    "scores = qbv_model.compute_scores(embedding_files, query_files)\n",
    "\n",
    "with open(\"scores.json\", \"w\") as f:\n",
    "    json.dump(scores, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
